<?xml version="1.0" encoding="UTF-8"?>
<FIMSAMECards xsi:noNamespaceSchemaLocation="../schema/FIMS-AME.xsd"
              xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
              xmlns:xs="http://www.w3.org/2001/XMLSchema">
  <AMECard>
    <CardID>A002</CardID>

    <Name>Speaker Diarization</Name>

    <Type>Audio</Type>

    <Status>draft</Status>

    <Editor>Werner</Editor>

    <Definition>Estimating the number of speakers present and say who is talking when (without the need to link speakers to external databases, just saying speaker A is talking at these times, speaker B at these)</Definition>

    <Parameters>
      <Inputs/>

      <Outputs>
        <Output>
          <Name>ListOfSpeakerSegments</Name>

          <Type>xml</Type>

          <Representation>urn:mpeg:mpeg7:2004:SegmentType urn:mpeg:mpeg7:part5:TextAnnotationType</Representation>

          <Definition>List of segments with start time, end time, speaker id (assigned labels within file) and confidence score</Definition>
        </Output>
      </Outputs>
    </Parameters>

    <CapabilityGroup name="speaker classes">
      <Capability>
        <Values>urn:oiweuowieruf</Values>

        <Type>supported speaker classes</Type>
      </Capability>
    </CapabilityGroup>

    <CapabilityGroup name="input formats">
      <Capability>
        <Values>urn:xyz</Values>

        <Type>supported audio formats</Type>
      </Capability>

      <Capability>
        <Values>urn:sdhfsdjkfh</Values>

        <Type>supported languages</Type>
      </Capability>
    </CapabilityGroup>
  </AMECard>
</FIMSAMECards>
