<?xml version="1.0" encoding="UTF-8"?>
<FIMSAMECards xsi:noNamespaceSchemaLocation="../schema/FIMS-AME.xsd"
              xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
              xmlns:xs="http://www.w3.org/2001/XMLSchema">
  <AMECard>
    <CardID>A003</CardID>
    <Name>Speaker Recognition</Name>
    <Type>Audio</Type>
    <Status>draft</Status>
    <Editor>Mike</Editor>
    <Definition>Given an external reference database of speakers, say who (if any) of the known speakers is speaking at a particular point in time</Definition>
    <Parameters>
      <Inputs>
        <Input>
          <Name>SpeakerDatabase</Name>
          <Type>xml</Type>
          <Representation/>
        </Input>
      </Inputs>
      <Outputs>
        <Output>
          <Name>ListOfSpeakerSegments</Name>
          <Type>xml</Type>
          <Representation/>
          <Comment>list of segments with start time, end time, speaker id and
          confidence score</Comment>
        </Output>
      </Outputs>
    </Parameters>
    <CapabilityGroup xsi:type="genericCapabilityGroupType" type="SpeakerRecognition">
			<Capability xsi:type="genericCapabilityType">
				<Values>...</Values>
				<Type>http://ebu.io/fims/ame/capabilities/speakerrecognition/classes</Type>
				<Unit>...</Unit>
			</Capability>
		</CapabilityGroup>
    <CapabilityGroup xsi:type="inputFormatCapabilityGroupType">
      <Capability xsi:type="audioFormatCapabilityType">
        <Values>urn:ebu:metadata-cs:FileFormatCS_2010</Values>
        <Type>http://ebu.io/fims/ame/capabilities/format/audio</Type>
      </Capability>
  	</CapabilityGroup>
	<CapabilityGroup xsi:type="audioCapabilityGroupType">
			<Capability xsi:type="audioLanguageCapabilityType">
				<Values>urn:iso:std:iso:639:-1 urn:iso:std:iso:639:-2</Values>
				<Type>http://ebu.io/fims/ame/capabilities/audio/language</Type>
			</Capability>
		</CapabilityGroup>    
  </AMECard>
</FIMSAMECards>
